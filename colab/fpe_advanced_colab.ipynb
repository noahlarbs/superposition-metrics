{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fixed Parameter Expansion (FPE) with Advanced Quantization\n",
                "\n",
                "This notebook runs the toy model experiment for splitting polysemantic neurons and applying advanced quantization (BitNet 1.58b ternary, iq2_xxs, q2_k) on the expanded connections, alongside KL divergence tracking and learning rate cooldown scheduling."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from torch import nn\n",
                "import torch.nn.functional as F\n",
                "import math\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "\n",
                "# Using GPU if available in Colab!\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Define Model and Metrics\n",
                "First, we define the `AdamW` optimizer, PR dimension computation, and our Fake Quantization logic."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import torch\n",
                "from torch.optim import Optimizer\n",
                "\n",
                "class AdamW(Optimizer):\n",
                "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-2, amsgrad=False):\n",
                "        if not 0.0 <= lr:\n",
                "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
                "        if not 0.0 <= eps:\n",
                "            raise ValueError(f\"Invalid epsilon value: {eps}\")\n",
                "        if not 0.0 <= betas[0] < 1.0:\n",
                "            raise ValueError(f\"Invalid beta parameter at index 0: {betas[0]}\")\n",
                "        if not 0.0 <= betas[1] < 1.0:\n",
                "            raise ValueError(f\"Invalid beta parameter at index 1: {betas[1]}\")\n",
                "        if not 0.0 <= weight_decay:\n",
                "            raise ValueError(f\"Invalid weight_decay value: {weight_decay}\")\n",
                "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad)\n",
                "        super(AdamW, self).__init__(params, defaults)\n",
                "\n",
                "    def __setstate__(self, state):\n",
                "        super(AdamW, self).__setstate__(state)\n",
                "        for group in self.param_groups:\n",
                "            group.setdefault('amsgrad', False)\n",
                "\n",
                "    @torch.no_grad()\n",
                "    def step(self, closure=None):\n",
                "        loss = None\n",
                "        if closure is not None:\n",
                "            with torch.enable_grad():\n",
                "                loss = closure()\n",
                "\n",
                "        for group in self.param_groups:\n",
                "            for p in group['params']:\n",
                "                if p.grad is None:\n",
                "                    continue\n",
                "\n",
                "                grad = p.grad\n",
                "                if grad.is_sparse:\n",
                "                    raise RuntimeError('AdamW does not support sparse gradients')\n",
                "                amsgrad = group['amsgrad']\n",
                "\n",
                "                state = self.state[p]\n",
                "\n",
                "                if len(state) == 0:\n",
                "                    state['step'] = 0\n",
                "                    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
                "                    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
                "                    if amsgrad:\n",
                "                        state['max_exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
                "\n",
                "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
                "                if amsgrad:\n",
                "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
                "                beta1, beta2 = group['betas']\n",
                "\n",
                "                state['step'] += 1\n",
                "                bias_correction1 = 1 - beta1 ** state['step']\n",
                "                bias_correction2 = 1 - beta2 ** state['step']\n",
                "\n",
                "                if group['weight_decay'] > 0:\n",
                "                    p.mul_(1 - group['lr'] * group['weight_decay'])\n",
                "                elif group['weight_decay'] < 0:\n",
                "                    p.add_(p, alpha=group['lr'] * -group['weight_decay'])\n",
                "\n",
                "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
                "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
                "                if amsgrad:\n",
                "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
                "                    denom = (max_exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
                "                else:\n",
                "                    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
                "\n",
                "                step_size = group['lr'] / bias_correction1\n",
                "                p.addcdiv_(exp_avg, denom, value=-step_size)\n",
                "\n",
                "        return loss\n",
                "\n",
                "def compute_pr_dim(activations):\n",
                "    if activations.dim() > 2:\n",
                "        activations = activations.reshape(-1, activations.shape[-1])\n",
                "    centered = activations - activations.mean(dim=0, keepdim=True)\n",
                "    cov = (centered.T @ centered) / (centered.shape[0] - 1)\n",
                "    eigenvalues = torch.linalg.eigvalsh(cov)\n",
                "    sum_eig = eigenvalues.sum()\n",
                "    if sum_eig.abs() < 1e-6:\n",
                "        return torch.tensor(0.0, device=activations.device)\n",
                "    sum_sq_eig = (eigenvalues ** 2).sum()\n",
                "    return (sum_eig ** 2) / sum_sq_eig\n",
                "\n",
                "WEIGHT_THRESHOLD = 1e-6\n",
                "\n",
                "def weight_quant_ternary(w):\n",
                "    scale = w.abs().mean().clamp(min=1e-8)\n",
                "    w_q = torch.round(w / scale).clamp(-1, 1) * scale\n",
                "    return w + (w_q - w).detach()\n",
                "\n",
                "def weight_quant_iq2_xxs(w):\n",
                "    scale = w.abs().mean().clamp(min=1e-8) * 2.5\n",
                "    norm_w = (w / scale).clamp(-1, 1)\n",
                "    signs = torch.sign(norm_w)\n",
                "    abs_w = norm_w.abs()\n",
                "    w_q_abs = torch.where(abs_w > 0.66, torch.ones_like(abs_w), torch.ones_like(abs_w) / 3.0)\n",
                "    w_q = signs * w_q_abs * scale\n",
                "    return w + (w_q - w).detach()\n",
                "\n",
                "def weight_quant_q2_k(w, block_size=32):\n",
                "    original_shape = w.shape\n",
                "    w_flat = w.flatten()\n",
                "    n_elements = w_flat.numel()\n",
                "    pad_size = (block_size - (n_elements % block_size)) % block_size\n",
                "    if pad_size > 0:\n",
                "        w_flat = F.pad(w_flat, (0, pad_size))\n",
                "    blocks = w_flat.view(-1, block_size)\n",
                "    scales = blocks.abs().max(dim=1, keepdim=True)[0].clamp(min=1e-8)\n",
                "    norm_blocks = blocks / scales\n",
                "    _, top_indices = torch.topk(norm_blocks.abs(), min(2, block_size), dim=1)\n",
                "    top_mask = torch.zeros_like(norm_blocks, dtype=torch.bool)\n",
                "    top_mask.scatter_(1, top_indices, True)\n",
                "    q4_blocks = torch.round(norm_blocks * 7.0) / 7.0\n",
                "    signs = torch.sign(norm_blocks)\n",
                "    abs_nb = norm_blocks.abs()\n",
                "    w_q_abs = torch.where(abs_nb > 0.66, torch.ones_like(abs_nb), torch.ones_like(abs_nb) / 3.0)\n",
                "    q2_blocks = signs * w_q_abs\n",
                "    q_blocks = torch.where(top_mask, q4_blocks, q2_blocks)\n",
                "    w_q_flat = q_blocks * scales\n",
                "    if pad_size > 0:\n",
                "        w_q_flat = w_q_flat[:-pad_size]\n",
                "    w_q = w_q_flat.view(original_shape)\n",
                "    return w + (w_q - w).detach()\n",
                "\n",
                "def activation_quant(x):\n",
                "    scale = 127.0 / x.abs().max().clamp(min=1e-8)\n",
                "    x_q = torch.round(x * scale).clamp(-128, 127) / scale\n",
                "    return x + (x_q - x).detach()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Core Model Architecture and Split Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class FeatureRecoveryAdvanced(nn.Module):\n",
                "    def __init__(self, n, m, W=None, b=None, expanded_indices=None, quant_method=\"ternary\"):\n",
                "        super().__init__()\n",
                "        self.n = n\n",
                "        self.m = m\n",
                "        if W is not None:\n",
                "            self.W = nn.Parameter(W.clone())\n",
                "        else:\n",
                "            self.W = nn.Parameter(torch.randn(n, m) / math.sqrt(m))\n",
                "        if b is not None:\n",
                "            self.b = nn.Parameter(b.clone())\n",
                "        else:\n",
                "            self.b = nn.Parameter(torch.randn(n))\n",
                "        self.relu = nn.ReLU()\n",
                "        self.expanded_indices = expanded_indices if expanded_indices is not None else []\n",
                "        self.quant_method = quant_method\n",
                "        \n",
                "    def quantize_w(self, w):\n",
                "        if self.quant_method == \"ternary\":\n",
                "            return weight_quant_ternary(w)\n",
                "        elif self.quant_method == \"iq2_xxs\":\n",
                "            return weight_quant_iq2_xxs(w)\n",
                "        elif self.quant_method == \"q2_k\":\n",
                "            return weight_quant_q2_k(w)\n",
                "        return w\n",
                "\n",
                "    def forward(self, x, return_hidden=False):\n",
                "        if len(self.expanded_indices) > 0:\n",
                "            mask = torch.zeros(self.m, device=self.W.device, dtype=torch.bool)\n",
                "            mask[self.expanded_indices] = True\n",
                "            \n",
                "            W_exp_q = self.quantize_w(self.W[:, mask])\n",
                "            W_continuous = self.W[:, ~mask]\n",
                "            \n",
                "            hidden_exp = activation_quant(x) @ W_exp_q\n",
                "            hidden_cont = x @ W_continuous\n",
                "            \n",
                "            hidden = torch.empty(x.shape[0], self.m, device=x.device, dtype=x.dtype)\n",
                "            hidden[:, mask] = hidden_exp\n",
                "            hidden[:, ~mask] = hidden_cont\n",
                "            \n",
                "            hidden_for_out = hidden.clone()\n",
                "            hidden_for_out[:, mask] = activation_quant(hidden[:, mask])\n",
                "            \n",
                "            output = self.relu(hidden_for_out[:, mask] @ W_exp_q.T + hidden_for_out[:, ~mask] @ W_continuous.T + self.b)\n",
                "        else:\n",
                "            hidden = x @ self.W\n",
                "            output = self.relu(hidden @ self.W.T + self.b)\n",
                "            \n",
                "        if return_hidden:\n",
                "            return output, hidden\n",
                "        return output\n",
                "\n",
                "def split_polysemantic_neurons(W, n_children=2, reference_W=None):\n",
                "    if reference_W is None:\n",
                "        reference_W = W\n",
                "    device = W.device\n",
                "    n, m = W.shape\n",
                "\n",
                "    new_columns = []\n",
                "    split_indices = []\n",
                "    expanded_indices = []\n",
                "    idx_counter = 0\n",
                "\n",
                "    for j in range(m):\n",
                "        w = W[:, j]\n",
                "        ref_w = reference_W[:, j]\n",
                "        nonzero_idx = (ref_w.abs() > WEIGHT_THRESHOLD).nonzero(as_tuple=True)[0]\n",
                "        if len(nonzero_idx) <= 1:\n",
                "            new_columns.append(w.unsqueeze(1))\n",
                "            idx_counter += 1\n",
                "        else:\n",
                "            split_indices.append(j)\n",
                "            idx_list = nonzero_idx.tolist()\n",
                "            n_conn = len(idx_list)\n",
                "            n_splits = min(n_children, n_conn)\n",
                "            base_size = n_conn // n_splits\n",
                "            remainder = n_conn % n_splits\n",
                "            offset = 0\n",
                "            for k in range(n_splits):\n",
                "                size = base_size + (1 if k < remainder else 0)\n",
                "                if size == 0: continue\n",
                "                part_idx = idx_list[offset : offset + size]\n",
                "                offset += size\n",
                "                w_child = torch.zeros(n, device=device, dtype=W.dtype)\n",
                "                for i in part_idx:\n",
                "                    w_child[i] = w[i]\n",
                "                new_columns.append(w_child.unsqueeze(1))\n",
                "                if k > 0: expanded_indices.append(idx_counter)\n",
                "                else: expanded_indices.append(idx_counter)\n",
                "                idx_counter += 1\n",
                "    if not new_columns:\n",
                "        return W, [], []\n",
                "    W_new = torch.cat(new_columns, dim=1)\n",
                "    return W_new, split_indices, expanded_indices\n",
                "\n",
                "def get_lr_cooldown(step, lr, total_steps, warmup_steps=2000, cooldown_ratio=0.5, min_lr=1e-5):\n",
                "    cooldown_start = int(total_steps * cooldown_ratio)\n",
                "    if step >= cooldown_start:\n",
                "        return min_lr\n",
                "    else:\n",
                "        eff_total = cooldown_start\n",
                "        step = step + 1\n",
                "        if step < warmup_steps:\n",
                "             return lr * step / warmup_steps\n",
                "        else:\n",
                "             progress = (step - warmup_steps) / (eff_total - warmup_steps)\n",
                "             return (lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress)) + min_lr\n",
                "\n",
                "def get_lr(step, lr, n_steps, warmup_steps=2000):\n",
                "    step = step + 1\n",
                "    min_lr = 0.05 * lr\n",
                "    if warmup_steps < n_steps:\n",
                "        if step < warmup_steps:\n",
                "            return lr * step / warmup_steps\n",
                "        else:\n",
                "            return (lr - min_lr) * 0.5 * (\n",
                "                1 + math.cos(math.pi * (step - warmup_steps) / (n_steps - warmup_steps))\n",
                "            ) + min_lr\n",
                "    else:\n",
                "        return (lr - min_lr) * 0.5 * (1 + math.cos(math.pi * step / n_steps)) + min_lr\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Loop Wrapper"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_experiment(quant_method=\"ternary\", n=1000, m=50, batch_size=2048, alpha=0.0,\n",
                "                   n_steps_pre=4000, n_steps_post=2000, eval_batch_size=8192, log_interval=500):\n",
                "    prob = torch.tensor([1.0 / i ** (1 + alpha) for i in range(1, n + 1)])\n",
                "    prob = prob / prob.sum()\n",
                "    prob = prob.to(device)\n",
                "\n",
                "    model = FeatureRecoveryAdvanced(n, m).to(device)\n",
                "    optimizer = AdamW([{\"params\": model.W, \"weight_decay\": -1.0}, {\"params\": model.b, \"weight_decay\": 0.0}], lr=1e-2)\n",
                "    criteria = nn.MSELoss()\n",
                "    \n",
                "    losses = []\n",
                "    pr_dims = []\n",
                "    \n",
                "    # PHASE 1: Strong Superposition Pre-Training\n",
                "    for step in range(n_steps_pre):\n",
                "        x = (torch.rand(batch_size, n, device=device) < prob) * torch.rand(batch_size, n, device=device) * 2\n",
                "        lr = get_lr(step, 1e-2, n_steps_pre)\n",
                "        for pg in optimizer.param_groups: pg[\"lr\"] = lr\n",
                "        optimizer.zero_grad()\n",
                "        y, hidden = model(x, return_hidden=True)\n",
                "        loss = criteria(y, x)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        with torch.no_grad(): pr_dim = compute_pr_dim(hidden.detach()).item()\n",
                "        losses.append(loss.item())\n",
                "        pr_dims.append(pr_dim)\n",
                "        if (step+1) % log_interval == 0:\n",
                "            print(f\"[{quant_method}] Phase 1 | Step {step+1}/{n_steps_pre} | Loss: {loss.item():.4e} PR: {pr_dim:.2f}\")\n",
                "\n",
                "    # INTERVENTION\n",
                "    W_old = model.W.detach()\n",
                "    W_new, split_indices, expanded_indices = split_polysemantic_neurons(W_old)\n",
                "    m_new = W_new.shape[1]\n",
                "    \n",
                "    model_full = FeatureRecoveryAdvanced(n, m_new, W=W_new, b=model.b.detach(), expanded_indices=[]).to(device)\n",
                "    optimizer_full = AdamW([{\"params\": model_full.W, \"weight_decay\": -1.0}, {\"params\": model_full.b, \"weight_decay\": 0.0}], lr=1e-2)\n",
                "    \n",
                "    model_quant = FeatureRecoveryAdvanced(n, m_new, W=W_new, b=model.b.detach(), expanded_indices=expanded_indices, quant_method=quant_method).to(device)\n",
                "    optimizer_quant = AdamW([{\"params\": model_quant.W, \"weight_decay\": -1.0}, {\"params\": model_quant.b, \"weight_decay\": 0.0}], lr=1e-2)\n",
                "\n",
                "    # Dummy steps for state initialization\n",
                "    for opt, mod in [(optimizer_full, model_full), (optimizer_quant, model_quant)]:\n",
                "        opt.zero_grad()\n",
                "        mod(torch.zeros(1, n, device=device)).sum().backward()\n",
                "        opt.step()\n",
                "    \n",
                "    # Momentum map\n",
                "    if len(optimizer.state) > 0:\n",
                "        old_state_W = optimizer.state[model.W]\n",
                "        if 'exp_avg' in old_state_W:\n",
                "            base_exp_avg, _, _ = split_polysemantic_neurons(old_state_W['exp_avg'], reference_W=W_old)\n",
                "            base_exp_avg_sq, _, _ = split_polysemantic_neurons(old_state_W['exp_avg_sq'], reference_W=W_old)\n",
                "            for opt, mod in [(optimizer_full, model_full), (optimizer_quant, model_quant)]:\n",
                "                opt.state[mod.W]['exp_avg'] = base_exp_avg.clone()\n",
                "                opt.state[mod.W]['exp_avg_sq'] = base_exp_avg_sq.clone()\n",
                "                opt.state[mod.W]['step'] = old_state_W['step']\n",
                "                opt.state[mod.b]['exp_avg'] = optimizer.state[model.b]['exp_avg'].clone()\n",
                "                opt.state[mod.b]['exp_avg_sq'] = optimizer.state[model.b]['exp_avg_sq'].clone()\n",
                "                opt.state[mod.b]['step'] = optimizer.state[model.b]['step']\n",
                "                \n",
                "    sparsity_mask = (model_full.W.abs() > 0).float()\n",
                "    losses_full = list(losses)\n",
                "    pr_dims_full = list(pr_dims)\n",
                "    losses_quant = list(losses)\n",
                "    pr_dims_quant = list(pr_dims)\n",
                "    kl_divs = []\n",
                "\n",
                "    n_steps_total = n_steps_pre + n_steps_post\n",
                "    # PHASE 2: Post-Intervention Tuning\n",
                "    for step in range(n_steps_pre, n_steps_total):\n",
                "        x = (torch.rand(batch_size, n, device=device) < prob) * torch.rand(batch_size, n, device=device) * 2\n",
                "        lr_full = get_lr(step, 1e-2, n_steps_total)\n",
                "        lr_quant = get_lr_cooldown(step - n_steps_pre, 1e-2, n_steps_post, warmup_steps=int(n_steps_post*0.2))\n",
                "\n",
                "        for pg in optimizer_full.param_groups: pg[\"lr\"] = lr_full\n",
                "        for pg in optimizer_quant.param_groups:\n",
                "            pg[\"lr\"] = lr_quant\n",
                "            # Cooldown weight decay dropoff based on BitNet\n",
                "            if step - n_steps_pre >= int(n_steps_post * 0.5):\n",
                "                pg[\"weight_decay\"] = 0.0\n",
                "\n",
                "        optimizer_full.zero_grad()\n",
                "        y_f, hidden_f = model_full(x, return_hidden=True)\n",
                "        loss_f = criteria(y_f, x)\n",
                "        loss_f.backward()\n",
                "        model_full.W.grad.data *= sparsity_mask\n",
                "        optimizer_full.step()\n",
                "\n",
                "        optimizer_quant.zero_grad()\n",
                "        y_q, hidden_q = model_quant(x, return_hidden=True)\n",
                "        loss_q = criteria(y_q, x)\n",
                "        loss_q.backward()\n",
                "        model_quant.W.grad.data *= sparsity_mask\n",
                "        optimizer_quant.step()\n",
                "\n",
                "        with torch.no_grad():\n",
                "            pr_dim_f = compute_pr_dim(hidden_f.detach()).item()\n",
                "            pr_dim_q = compute_pr_dim(hidden_q.detach()).item()\n",
                "            log_pseudo_q = F.log_softmax(y_q, dim=-1)\n",
                "            pseudo_f = F.softmax(y_f, dim=-1)\n",
                "            kl = F.kl_div(log_pseudo_q, pseudo_f, reduction='batchmean').item()\n",
                "\n",
                "        losses_full.append(loss_f.item())\n",
                "        pr_dims_full.append(pr_dim_f)\n",
                "        losses_quant.append(loss_q.item())\n",
                "        pr_dims_quant.append(pr_dim_q)\n",
                "        kl_divs.append(kl)\n",
                "\n",
                "        if (step+1) % log_interval == 0:\n",
                "            print(f\"[{quant_method}] Phase 2 | Step {step+1}/{n_steps_total} | F-Loss: {loss_f.item():.4e} Q-Loss: {loss_q.item():.4e} | KL: {kl:.4e}\")\n",
                "\n",
                "    return {\n",
                "        \"losses_full\": losses_full,\n",
                "        \"pr_dims_full\": pr_dims_full,\n",
                "        \"losses_quant\": losses_quant,\n",
                "        \"pr_dims_quant\": pr_dims_quant,\n",
                "        \"kl_divs\": kl_divs,\n",
                "        \"n_steps_pre\": n_steps_pre,\n",
                "        \"n_steps_post\": n_steps_post\n",
                "    }\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Iterations and Plot\n",
                "Run the iterations for each quantization style and display the multi-plot directly!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "methods = [\"ternary\", \"iq2_xxs\", \"q2_k\"]\n",
                "results = {}\n",
                "for method in methods:\n",
                "    results[method] = run_experiment(quant_method=method)\n",
                "\n",
                "ref = results[\"ternary\"]\n",
                "losses_full = ref[\"losses_full\"]\n",
                "pr_dims_full = ref[\"pr_dims_full\"]\n",
                "split_step = ref[\"n_steps_pre\"]\n",
                "total_steps = split_step + ref[\"n_steps_post\"]\n",
                "steps_full = range(len(losses_full))\n",
                "kl_steps = range(split_step, total_steps)\n",
                "    \n",
                "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "# Plot Loss\n",
                "ax1.plot(steps_full, losses_full, label=\"FPE (Full Precision)\", color=\"black\", linestyle=\"--\")\n",
                "for method in methods:\n",
                "    ax1.plot(steps_full, results[method][\"losses_quant\"], label=f\"FPE ({method})\")\n",
                "ax1.axvline(x=split_step, color='red', linestyle=':', label='FPE Intervention')\n",
                "ax1.set_xlabel('Training Step')\n",
                "ax1.set_ylabel('Loss (MSE)')\n",
                "ax1.set_title('Training Loss')\n",
                "ax1.set_yscale('log')\n",
                "ax1.legend()\n",
                "\n",
                "# Plot PR Dimension\n",
                "ax2.plot(steps_full, pr_dims_full, label=\"FPE (Full Precision)\", color=\"black\", linestyle=\"--\")\n",
                "for method in methods:\n",
                "    ax2.plot(steps_full, results[method][\"pr_dims_quant\"], label=f\"FPE ({method})\")\n",
                "ax2.axvline(x=split_step, color='red', linestyle=':', label='FPE Intervention')\n",
                "ax2.set_xlabel('Training Step')\n",
                "ax2.set_ylabel('Participation Ratio ($D_{PR}$)')\n",
                "ax2.set_title('Intrinsic Dimensionality')\n",
                "ax2.legend()\n",
                "\n",
                "# Plot KL Divergences\n",
                "for method in methods:\n",
                "    ax3.plot(kl_steps, results[method][\"kl_divs\"], label=f\"KL Div ({method})\")\n",
                "ax3.set_xlabel('Training Step')\n",
                "ax3.set_ylabel('KL Divergence')\n",
                "ax3.set_title('KL Divergence against Full-Weight')\n",
                "ax3.set_yscale('log')\n",
                "ax3.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.5"
        }
    }
